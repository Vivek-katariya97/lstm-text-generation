{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66fad105-4170-4a99-af37-844489e98f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a544cd-5d1f-4249-a6a7-a7c59b176583",
   "metadata": {},
   "source": [
    "Loading Shakespeare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb324b7f-f00d-4ca8-a843-7c3d4615a2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in raw dataset: 5458199\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "print(\"Total characters in raw dataset:\", len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b27f62b-98b3-46a0-b7bb-bd94d7ea1a4e",
   "metadata": {},
   "source": [
    "# Remove Gutenberg header text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bf9a993-718a-4f74-a851-0a59161e3865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters after cleaning: 5447737\n"
     ]
    }
   ],
   "source": [
    "start_index = text.find(\"the sonnets\")\n",
    "text = text[start_index:]\n",
    "\n",
    "print(\"Total characters after cleaning:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297c04d2-bea9-4202-8359-442bcb892fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 27141\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(\"Total unique words:\", total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f65ca2dc-9f43-48ad-b82f-9c90662d454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "\n",
    "for line in text.split(\"\\n\"):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        input_sequences.append(token_list[:i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b4674ae-240c-4084-9b75-9043fe3207cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (790577, 16)\n",
      "Label shape: (790577,)\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences\n",
    "max_sequence_len = max(len(seq) for seq in input_sequences)\n",
    "\n",
    "input_sequences = pad_sequences(\n",
    "    input_sequences,\n",
    "    maxlen=max_sequence_len,\n",
    "    padding='pre'\n",
    ")\n",
    "\n",
    "# Split inputs and labels\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]\n",
    "\n",
    "print(\"Input shape:\", X.shape)\n",
    "print(\"Label shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d80c1d8-c888-4a39-83ef-ec0e237f03ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced input shape: (200000, 16)\n",
      "Reduced label shape: (200000,)\n"
     ]
    }
   ],
   "source": [
    "X = X[:200000]\n",
    "y = y[:200000]\n",
    "\n",
    "print(\"Reduced input shape:\", X.shape)\n",
    "print(\"Reduced label shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a565f32-169d-4886-97e7-1ed4ffc52606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(total_words, 100, input_length=max_sequence_len - 1),\n",
    "    LSTM(150),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3113beab-d3cd-42a1-bac0-2a70ce9811e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 113ms/step - accuracy: 0.0398 - loss: 6.8950\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 113ms/step - accuracy: 0.0697 - loss: 6.3478\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 113ms/step - accuracy: 0.0970 - loss: 6.0129\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 122ms/step - accuracy: 0.1121 - loss: 5.7706\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 119ms/step - accuracy: 0.1234 - loss: 5.5701\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 115ms/step - accuracy: 0.1297 - loss: 5.3858\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 112ms/step - accuracy: 0.1361 - loss: 5.2118\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 111ms/step - accuracy: 0.1426 - loss: 5.0461\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 112ms/step - accuracy: 0.1497 - loss: 4.8900\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 110ms/step - accuracy: 0.1577 - loss: 4.7422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1dc1bd95550>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "935b5bd1-decb-4c8d-bbab-54fb7d73e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_with_temperature(seed_text, next_words=30, temperature=0.8):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences(\n",
    "            [token_list],\n",
    "            maxlen=max_sequence_len - 1,\n",
    "            padding='pre'\n",
    "        )\n",
    "\n",
    "        predictions = model.predict(token_list, verbose=0)[0]\n",
    "        predictions = np.log(predictions + 1e-9) / temperature\n",
    "        exp_preds = np.exp(predictions)\n",
    "        predictions = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        predicted_index = np.random.choice(len(predictions), p=predictions)\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                seed_text += \" \" + word\n",
    "                break\n",
    "\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fa6a4b3-da67-4777-9a10-2c1fe1980f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature = 0.5 (More Safe)\n",
      "shall i compare thee to a summer and i know it is a good good lord and you sir john i 'my wife to me and i am the chain of me there is it the queen\n",
      "\n",
      "Temperature = 0.8 (Balanced)\n",
      "shall i compare thee to a summer world with good mind i will please you none no i heard it for before you for my view he embark'd and you have done sir for't is i am\n",
      "\n",
      "Temperature = 1.2 (More Creative)\n",
      "shall i compare thee to a summer helen half possess'd hard good let i see antony god's sake hath prove my dearest steed then unto him still we publish seek him as your own semblance follow saying\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"shall i compare thee to a summer\"\n",
    "\n",
    "print(\"Temperature = 0.5 (More Safe)\")\n",
    "print(generate_text_with_temperature(seed_text, 30, temperature=0.5))\n",
    "\n",
    "print(\"\\nTemperature = 0.8 (Balanced)\")\n",
    "print(generate_text_with_temperature(seed_text, 30, temperature=0.8))\n",
    "\n",
    "print(\"\\nTemperature = 1.2 (More Creative)\")\n",
    "print(generate_text_with_temperature(seed_text, 30, temperature=1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3b902-e2a5-4378-8d93-4e738e3e83cd",
   "metadata": {},
   "source": [
    "Lower temperature values generate safer and more repetitive text,\n",
    "while higher values increase creativity at the cost of grammatical correctness.\n",
    "A temperature of 0.8 provides the best balance between coherence and diversity.\n",
    "\n",
    "Due to hardware limitations, the dataset size was capped while preserving\n",
    "the overall language structure and learning behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61fdc68-f53f-4374-a589-3f3a19da5edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
